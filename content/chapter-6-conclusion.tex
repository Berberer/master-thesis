% !TEX root = ../my-thesis.tex
%
\chapter{Conclusion}
\label{sec:conclusion}
In this final chapter after answering the concrete research questions of the thesis previously, the prior descriptions and findings regarding the optimizer ensemble AutoML approach are summarized and concluded with an outlook of possible future works.

\section{Summary and Findings}
\label{sec:conclusion:summary}
This thesis was based on the statements of the No-Free-Lunch theorems for optimization, which had proven that under given constraints no optimization algorithm can be superior for all problems.
To approach this problem, the model selection of an AutoML setting combined with choosing an optimizer that should perform a model configuration for the selected pipeline model was seen as a joint and hierarchical Multi-Armed Bandit problem.
Hence, it was tackled with a MCTS, which searches a model selection graph that is realized as a HTN planning graph with embedded optimizers to achieve the joint Bandit Problem.
This optimizers are combined as an ensemble to utilize each others gathered information about evaluated candidates and perform successive warmstarting for each optimization run.

This novelle AutoML idea was realized as a first simple reference implementation, which afterwards was used in a series of experiments to examine the feasibility of the approach and to gather additional knowledge about the functionality of the components.

In its current reference implementation the approach of this thesis was not able to surpass the currently best state-of-the-art approaches auto-sklearn and TPOT for the examined datasets.
However, it was able to show competitive results for some of the datasets which could indicate the potential to close the current gap between the tools or even surpass them.

\section{Open Questions and Future Work}
Besides the mentioned further development regarding general implementation maturity and optimization, some other factors, which could lead to better results, were not covered by this thesis and are good starting points for future work.
To round off this chapter, they are listed in the following, grouped into different categories:
\begin{itemize}
    \item \textbf{Configuration}: The evaluation was solely done with one configuration of this approach.
    Although the utilized configuration showed the best results in some tests prior to the experiments, there may exist even better configuration for example regarding the amount of Monte-Carlo simulations or the time budget of each single optimization run.
    A thorough study of a variety of possible configurations in the context of different AutoML timeouts and more datasets than the evaluated ten, can be a first next step.\newline
    Additionally, the configuration of this approach remained static during the entire MCTS search.
    Modifying the configuration values during the search, could improve the balance between exploration and exploitation.
    For example, the amount of Monte-Carlo simulation could start with a high value and be reduces during the run to reach a higher coverage in the beginning of the initial exploration of the search space.
    Or alternatively the optimization time budget could start with a low value and be improved later in the search, once the probability of exploiting more suitable optimizers is higher after a certain degree of exploration.
    \item \textbf{Model Selection Search}: During the evaluation of different configurations, it could also prove worthwhile to evaluate different search algorithms instead of a MCTS.
    Since the variant of this approach that used a random search instead of MCTS was not significantly worse, other search algorithms should also be considered and tested.\newline
    Although MCTS is usually associated with UCT as a policy for scoring nodes, there are also other published MCTS policies for scoring nodes and selecting them accordingly.
    A survey of a broad selection of such policies was for example done by~\textcite{Browne-Policies}.
    Besides completely different search algorithms, a study of different MCTS variations and policies could also be worth doing.
    \item \textbf{Optimizer Ensemble Model Configuration}: In the case of the evaluated datasets, MCTS rarely exploited a random search or Discretization Search for optimization in comparison to the other optimizers.
    If this is also the case during a broader study of more datasets, the subset of optimizers that are selected for the ensemble, could be reduces to the remaining three optimizers, or alternatively the two optimizers could be replaced by other optimizers, which were not integrated and evaluated yet.\newline
    Besides the selection of optimizers for the ensembles, the interaction within the ensembles is also a starting point for future research.
    It has to be evaluated if every optimizer really profits from warmstarting or if this leads to an over-searching of local optima for example.
    Similar to adjusting the configuration dynamically during the run, it could is also a different approach to enable or disable warmstarting for different time periods of the overall search or for different parts of the search graph.\newline
    Additionally, the possibilities for modelling the model configuration optimization spaces can be extended to a degree of the expressiveness of auto-sklearns space modelling features.
    Constraints across multiple parameters like for example, "\textit{If value $a$ is selected for parameter $p_1$, value $b$ is no longer an allowed value for parameter $p_2$}" could prevent this approach from evaluating unsuitable or even invalid pipeline parametrization candidates.
\end{itemize}
